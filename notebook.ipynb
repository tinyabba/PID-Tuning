{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import dstep, dlti\n",
    "\n",
    "import experimental.utils as utils\n",
    "from experimental.agent import PIDTuningAgent\n",
    "from experimental.environment import PIDTuningEnvironment\n",
    "from experimental.runner import Runner\n",
    "from experimental.runner_opt import Runner_opt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose testcase and experiment\n",
    "testcase = 5\n",
    "experiment = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open json file\n",
    "\n",
    "f = open(f'config/testcase_synt_{testcase}.json')\n",
    "param_dict = json.load(f)\n",
    "\n",
    "horizon = param_dict['horizon']\n",
    "n_trials = param_dict['n_trials']\n",
    "sigma = param_dict['noise_sigma']\n",
    "\n",
    "n = param_dict['n']\n",
    "p = param_dict['p']\n",
    "m = param_dict['m']\n",
    "\n",
    "A = np.array(param_dict['A'])\n",
    "b = np.array(param_dict['B'])\n",
    "c = np.array(param_dict['C'])\n",
    "\n",
    "#Step signal\n",
    "y_0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dictionary for the errors of the algorithms\n",
    "optimal = \"optimal\"\n",
    "pidtuning = \"pidtuning\"\n",
    "ziegler_nichols = \"ziegler_nichols\"\n",
    "alg_list = [optimal, pidtuning, ziegler_nichols]\n",
    "errors = {alg: np.zeros((n_trials, horizon)) for alg in alg_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define noises\n",
    "np.random.seed(1)\n",
    "noise = np.random.normal(0, sigma, (n_trials, horizon, n))\n",
    "out_noise = np.random.normal(0, sigma, (n_trials, horizon, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define range of possible PID parameters\n",
    "log_space = np.logspace(0, 1, num=16, base=10)\n",
    "\n",
    "K_P_range_start = 0.0\n",
    "K_P_range_end = 3\n",
    "K_P_range = (log_space - log_space.min()) / (log_space.max() - log_space.min()) *\\\n",
    "      (K_P_range_end - K_P_range_start) + K_P_range_start\n",
    "\n",
    "K_I_range_start = 0.0\n",
    "K_I_range_end = 3\n",
    "K_I_range = (log_space - log_space.min()) / (log_space.max() - log_space.min()) *\\\n",
    "      (K_I_range_end - K_I_range_start) + K_I_range_start\n",
    "\n",
    "K_D_range_start = 0.0\n",
    "K_D_range_end = 1\n",
    "K_D_range = (log_space - log_space.min()) / (log_space.max() - log_space.min()) *\\\n",
    "      (K_D_range_end - K_D_range_start) + K_D_range_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build list of ammissible PID parameters\n",
    "pid_actions = []\n",
    "for K in list(itertools.product(K_P_range, K_I_range, K_D_range)):\n",
    "    bar_A = utils.compute_bar_a(A, b, c, K)\n",
    "    if (np.max(np.absolute(np.linalg.eigvals(bar_A))) < 0.4): \n",
    "        pid_actions.append(np.array(K).reshape(3,1))\n",
    "\n",
    "pid_actions = np.array(pid_actions)\n",
    "n_arms = pid_actions.shape[0]\n",
    "print(n_arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_arms)\n",
    "print(np.max(pid_actions[:,0,:]))\n",
    "print(np.max(pid_actions[:,1,:]))\n",
    "print(np.max(pid_actions[:,2,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run optimal algorithm\n",
    "\n",
    "env = PIDTuningEnvironment(A, b, c, n, p, m, y_0, horizon, noise, out_noise, n_trials)\n",
    "print('Running Optimal algorithm')\n",
    "\n",
    "all_errors = np.zeros((n_arms, n_trials, horizon))\n",
    "np.save(\"optimal_errors1.npy\", all_errors)\n",
    "all_SSE = np.zeros((n_arms, n_trials))\n",
    "K_opt_idx = np.zeros(n_trials)\n",
    "K_opt = np.zeros((n_trials, 3, 1))\n",
    "for i, K in enumerate(pid_actions):\n",
    "    print(\"Running simulation \", i)\n",
    "    runner_opt = Runner_opt(env, n_trials, horizon, 3, n_arms, pid_actions)\n",
    "    all_errors[i] = runner_opt.perform_simulations(K, i)\n",
    "    for trial_i in range(n_trials):\n",
    "        all_SSE[i, trial_i] = np.sum(all_errors[i, trial_i]**2)\n",
    "for trial_i in range(n_trials):\n",
    "    K_opt_idx[trial_i] = np.argmin(all_SSE[:, trial_i])\n",
    "    K_opt[trial_i] = pid_actions[int(K_opt_idx[trial_i])]\n",
    "    errors[optimal][trial_i,:] = all_errors[int(K_opt_idx[trial_i]), trial_i, :]\n",
    "np.save(\"optimal_errors1.npy\", errors[optimal])\n",
    "np.save(\"K_opt_idx_1\", K_opt_idx)\n",
    "np.save(\"K_opt_1\", K_opt)\n",
    "np.save(\"all_errors_1.npy\", all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot K_P and SSE, fixed K_I and K_D\n",
    "idx = []\n",
    "for i, K in enumerate(pid_actions):\n",
    "    if (K[1] == K_opt[0][1] and K[2] == K_opt[0][2]):\n",
    "        idx.append(i)\n",
    "y_plot = []\n",
    "x_plot = []\n",
    "for i in idx:\n",
    "    y_plot.append(all_SSE[i][0])\n",
    "    x_plot.append(pid_actions[i][0][0])\n",
    "\n",
    "print(K_opt[0][0][0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(x_plot), np.array(y_plot))\n",
    "plt.xlabel('K_P')\n",
    "plt.ylabel('SSE')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot K_D and SSE, fixed K_P and K_I\n",
    "idx = []\n",
    "for i, K in enumerate(pid_actions):\n",
    "    if (K[0] == K_opt[0][0] and K[1] == K_opt[0][1]):\n",
    "        idx.append(i)\n",
    "y_plot = []\n",
    "x_plot = []\n",
    "for i in idx:\n",
    "    y_plot.append(all_SSE[i][0])\n",
    "    x_plot.append(pid_actions[i][2][0])\n",
    "\n",
    "print(K_opt[0][2][0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(x_plot), np.array(y_plot))\n",
    "plt.xlabel('K_D')\n",
    "plt.ylabel('SSE')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot K_I parameters and SSE, fixed K_P and K_D\n",
    "idx = []\n",
    "for i, K in enumerate(pid_actions):\n",
    "    if (K[0][0] == K_opt[0][0][0] and K[2][0] == K_opt[0][2][0]):\n",
    "        idx.append(i)\n",
    "y_plot = []\n",
    "x_plot = []\n",
    "for i in idx:\n",
    "    y_plot.append(all_SSE[i][0])\n",
    "    x_plot.append(pid_actions[i][1][0])\n",
    "\n",
    "print(K_opt[0][1][0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(x_plot), np.array(y_plot))\n",
    "plt.xlabel('K_I')\n",
    "plt.ylabel('SSE')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziegler-Nichols open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load .mat file containing step response\n",
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat('step_response.mat')\n",
    "data = mat['data']\n",
    "\n",
    "y_zn = data[:, 1]\n",
    "print(np.shape(y_zn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute step response\n",
    "\n",
    "d = np.array([0])\n",
    "system = dlti(A, b, c, d, dt=True)\n",
    "t = np.arange(horizon)\n",
    "_, y_zn = dstep(system, t=t)\n",
    "y_zn = np.squeeze(y_zn)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(t, y_zn)\n",
    "plt.title('Step Response')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Output')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running step response simulation\n",
    "\n",
    "from experimental.environment_step import StepEnvironment\n",
    "from experimental.runner_step import RunnerStep\n",
    "\n",
    "experiment_zn = 1\n",
    "all_outputs = np.zeros((n_trials, horizon))\n",
    "np.savez_compressed(f\"step_{experiment_zn}.npz\", all_outputs = all_outputs)\n",
    "env = StepEnvironment(A, b, c, n, p, m, y_0, horizon, noise, out_noise, n_trials)\n",
    "print('Running step response simulation')\n",
    "runner = RunnerStep(env,  n_trials, horizon)\n",
    "all_outputs = runner.perform_simulations(y_0, experiment_zn)\n",
    "np.savez_compressed(f\"step_{experiment_zn}.npz\", all_outputs = all_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot mean step response\n",
    "output_mean = np.mean(all_outputs, axis=0)\n",
    "output_std = np.std(all_outputs, axis=0) / np.sqrt(n_trials)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(output_mean, label='Step response mean')\n",
    "plt.fill_between(range(len(output_mean)), \n",
    "                 output_mean - output_std, \n",
    "                 output_mean + output_std, \n",
    "                 color='b', alpha=0.2, label='Step response std')\n",
    "plt.title('Step Response')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute regret for Ziegler-Nichols algorithm\n",
    "\n",
    "inst_regret_zn = np.zeros(horizon)\n",
    "cum_regret_zn = np.zeros(horizon)\n",
    "\n",
    "errors[ziegler_nichols] = y_0 - all_outputs\n",
    "inst_regret_zn = np.zeros((n_trials, horizon))\n",
    "cum_regret_zn = np.zeros((n_trials, horizon))\n",
    "inst_regret_zn =  errors[ziegler_nichols]**2 - errors[optimal][:,0:horizon]**2\n",
    "for trial_i in range(n_trials):\n",
    "    cum_regret_zn[trial_i] = np.cumsum(inst_regret_zn[trial_i])\n",
    "cum_regret_mean_zn = np.mean(cum_regret_zn, axis=0)\n",
    "cum_regret_std_zn = np.std(cum_regret_zn, axis=0) / np.sqrt(n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot cumulative mean regret with std deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(cum_regret_mean_zn, label='Ziegler-Nichols')\n",
    "plt.fill_between(range(len(cum_regret_mean_zn)), \n",
    "                 cum_regret_mean_zn - cum_regret_std_zn, \n",
    "                 cum_regret_mean_zn + cum_regret_std_zn, \n",
    "                 color='b', alpha=0.2, label='Standard Error Ziegler-Nichols')\n",
    "\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Cumulative mean regret with standard deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PID Tuning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper bound for relevant quantities\n",
    "action_max = pid_actions[np.argmax([np.linalg.norm(np.array(K), 2) for K in pid_actions])]\n",
    "K_val = np.linalg.norm(action_max, 2)\n",
    "b_val = np.linalg.norm(b, 2)\n",
    "c_val = np.linalg.norm(c, 2)\n",
    "spectral_rad_ub = max(np.linalg.eigvals(A))\n",
    "phi_a_ub = utils.spectr(A)\n",
    "y_0 = 1\n",
    "\n",
    "\n",
    "#Upper bound for noise\n",
    "noise_norm = []\n",
    "for trial_i in range(n_trials):\n",
    "    for t in range(horizon):\n",
    "        noise_norm.append(np.linalg.norm(noise[trial_i, t, :]))\n",
    "        noise_norm.append(np.linalg.norm(out_noise[trial_i, t, :]))\n",
    "noise_ub = max(np.array(noise_norm))\n",
    "\n",
    "\n",
    "#Upper bound for spectral radius of matrix bar_A\n",
    "spectral_rad_list = []\n",
    "for K in pid_actions:\n",
    "    bar_A = utils.compute_bar_a(A, b, c, K)\n",
    "    spectral_rad_list.append(np.max(np.absolute(np.linalg.eigvals(bar_A))))\n",
    "\n",
    "spectral_rad_bar_ub = np.max(np.array(spectral_rad_list))\n",
    "bar_A = utils.compute_bar_a(A, b, c, pid_actions[np.argmax(np.array(spectral_rad_list))])\n",
    "phi_bar_a_ub = utils.spectr(bar_A)\n",
    "\n",
    "print(spectral_rad_bar_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create file for PIDTuning algorithm checkpoints\n",
    "#It saves the error at each time, for each simulation\n",
    "#It works even with interruptions\n",
    "temp = np.zeros((n_trials, horizon))\n",
    "np.save(\"pid_tuning_errors_1.npy\", temp)\n",
    "temp = np.zeros((n_trials, horizon, 3, 1))\n",
    "np.save(\"pulled_arms_1.npy\", temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running PIDTuning\n",
    "agent = PIDTuningAgent(n_arms, pid_actions, horizon,\n",
    "                            np.log(horizon), b_val, c_val, K_val, phi_a_ub, phi_bar_a_ub, y_0,\n",
    "                            spectral_rad_ub, spectral_rad_bar_ub, noise_ub, sigma)\n",
    "env = PIDTuningEnvironment(A, b, c, n, p, m, y_0, horizon, noise, out_noise, n_trials)\n",
    "print('Running PID Tuning')\n",
    "runner = Runner(env, agent, n_trials, horizon, 3, n_arms, pid_actions)\n",
    "errors[pidtuning] = runner.perform_simulations()\n",
    "np.save(\"pid_tuning_errors1.npy\", errors[pidtuning])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "errors[pidtuning] = np.load(f'.\\experiments\\experiment_{experiment}\\pid_tuning_errors{experiment}.npy', allow_pickle=True)\n",
    "if (experiment!=1):\n",
    "    loaded = np.load(f\".\\experiments\\experiment_{experiment}\\experiment_{experiment}.npz\", allow_pickle=True)\n",
    "    errors[optimal] = loaded['optimal_errors']\n",
    "    K_opt = loaded['K_opt']\n",
    "    K_opt_idx = loaded['K_opt_idx']\n",
    "    pid_actions = loaded['pid_actions']\n",
    "else:\n",
    "    errors[optimal] = np.load(\".\\experiments\\experiment_1\\optimal_errors1.npy\", allow_pickle=True)\n",
    "    K_opt = np.load(\".\\experiments\\experiment_1\\K_opt_1.npy\", allow_pickle=True)\n",
    "    K_opt_idx = np.load(\".\\experiments\\experiment_1\\K_opt_idx_1.npy\", allow_pickle=True)\n",
    "\n",
    "print(np.shape(errors[pidtuning]))\n",
    "print(np.shape(errors[optimal]))\n",
    "print(K_opt_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute regret for PIDTuning\n",
    "inst_regret = np.zeros((n_trials, horizon))\n",
    "cum_regret = np.zeros((n_trials, horizon))\n",
    "\n",
    "inst_regret =  errors[pidtuning]**2 - errors[optimal][:,0:horizon]**2\n",
    "for trial_i in range(n_trials):\n",
    "    cum_regret[trial_i] = np.cumsum(inst_regret[trial_i])\n",
    "cum_regret_mean = np.mean(cum_regret, axis=0)\n",
    "cum_regret_std = np.std(cum_regret, axis=0) / np.sqrt(n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot cumulative mean regret with std deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(cum_regret_mean, label='PIDTuning')\n",
    "plt.fill_between(range(len(cum_regret_mean)), \n",
    "                 cum_regret_mean - cum_regret_std, \n",
    "                 cum_regret_mean + cum_regret_std, \n",
    "                 color='b', alpha=0.2, label='Standard Error PIDTuning')\n",
    "\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Cumulative mean regret with standard deviation\")\n",
    "plt.show()\n",
    "\n",
    "#Plot all simulations\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_trials):\n",
    "    label = str(i)\n",
    "    plt.plot(cum_regret[i], label=label)\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Cumulative regret for each simulation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot cumulative mean regret with std deviation fro PIDTuning and Ziegler-Nichols\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(cum_regret_mean, label='PIDTuning')\n",
    "plt.fill_between(range(len(cum_regret_mean)), \n",
    "                 cum_regret_mean - cum_regret_std, \n",
    "                 cum_regret_mean + cum_regret_std, \n",
    "                 color='b', alpha=0.2, label='Standard Error PIDTuning')\n",
    "\n",
    "plt.plot(cum_regret_mean_zn, label='Ziegler-Nichols')\n",
    "plt.fill_between(range(len(cum_regret_mean_zn)), \n",
    "                 cum_regret_mean_zn - cum_regret_std_zn, \n",
    "                 cum_regret_mean_zn + cum_regret_std_zn, \n",
    "                 color='b', alpha=0.2, label='Standard Error Ziegler-Nichols')\n",
    "\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Cumulative mean regret with standard deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all simulations except simulation 1\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_trials):\n",
    "    if(i!=1):\n",
    "        plt.plot(cum_regret[i], label=str(i))\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Plot only simulation 1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cum_regret[1], label=\"Simulation 1\")\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pulled PID actions\n",
    "pulled_arms = np.load(f\".\\experiments\\experiment_{experiment}\\pulled_arms_{experiment}.npy\", allow_pickle=True)\n",
    "pulled_arms = pulled_arms.reshape(n_trials, horizon, 3)\n",
    "pid_actions_reshaped = pid_actions.reshape(len(pid_actions), 3)\n",
    "\n",
    "list = np.zeros((n_trials, horizon))\n",
    "for sim_i in range(n_trials):\n",
    "    for t in range(horizon):\n",
    "        match = np.all(pid_actions_reshaped == pulled_arms[sim_i, t], axis=1)\n",
    "        index = np.where(match)[0]\n",
    "        list[sim_i, t] = index\n",
    "\n",
    "sim = 9\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(np.arange(horizon), list[sim], s=10)\n",
    "plt.grid(True)\n",
    "plt.yticks(range(0, len(pid_actions)))\n",
    "plt.xticks(range(0, horizon, int(horizon/10)))\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('PID action index')\n",
    "plt.title(f\"Pulled PID actions in simulation {sim}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = np.shape(pid_actions)[0]\n",
    "inst_regret = np.zeros((n_trials, horizon*10))\n",
    "cum_regret = np.zeros((n_trials, horizon*10))\n",
    "all_errors = loaded['all_errors']\n",
    "all_SSE = np.zeros((n_arms, n_trials))\n",
    "for i in range(n_arms):\n",
    "    for sim_i in range(n_trials):\n",
    "        all_SSE[i, sim_i] = np.sum(all_errors[i, sim_i]**2)\n",
    "\n",
    "inst_regret =  all_errors[4]**2 - errors[optimal] **2\n",
    "for trial_i in range(n_trials):\n",
    "    cum_regret[trial_i] = np.cumsum(inst_regret[trial_i])\n",
    "\n",
    "#Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(cum_regret[1], label='PIDTuning')\n",
    "\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(pid_actions)):\n",
    "    inst_regret =  all_errors[i]**2\n",
    "    inst_regret_mean = np.mean(inst_regret, axis=0)\n",
    "    plt.plot(inst_regret_mean[20:], label=i, alpha=0.1)\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
